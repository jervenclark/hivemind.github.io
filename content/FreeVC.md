> In this [paper](https://arxiv.org/abs/2210.15418), we adopt the end-to-end framework of [VITS](https://arxiv.org/abs/2106.06103) for high-quality waveform reconstruction, and propose strategies for clean content information extraction without text annotation. We disentangle content information by imposing an information bottleneck to [WavLM](https://arxiv.org/abs/2110.13900) features, and propose the **spectrogram-resize** based data augmentation to improve the purity of extracted content information.

## Notes
### Resources
- [https://github.com/jaywalnut310/vits](https://github.com/jaywalnut310/vits)
- [https://github.com/microsoft/unilm/tree/master/wavlm](https://github.com/microsoft/unilm/tree/master/wavlm)
- [https://github.com/jik876/hifi-gan](https://github.com/jik876/hifi-gan)
- [https://github.com/liusongxiang/ppg-vc](https://github.com/liusongxiang/ppg-vc)
### Further Readings
- [[FreeVC꞉ Towards High-Quality Text-Free One-Shot Voice Conversion.pdf]]
- [[Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech.pdf]]
- [[WavLM꞉ Large-Scale Self-Supervised Pre-Training for Full Stack Speech Processing.pdf]]