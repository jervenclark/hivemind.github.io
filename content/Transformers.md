Transformers are a revolutionary type of [[Neural Network Architecture]] in [[Machine Learning (ML)|Machine Learning]], specifically designed for [[Sequence-to-sequence]] tasks. Unlike previous Models, they rely on a mechanism called [[Attention Mechanism|Attention]] to understand the relationship between elements in a sequence like words in a sentence. This makes them particularly powerful for tasks involving [[Natural Language Processing (NLP)]].

## What do they do?
- transform or change an input sequence (e.g. text) into an output sequence (e.g. translation, summary)
- understand context and relationships between elements in the sequence, thanks to the attention mechanism
- learn without relying on recurrent units (like [[Long-Short Term Memory (LSTM)]]), leading to faster training times.

## Applications
- [[Natural Language Processing (NLP)]]:
	- [[Machine Translation]]
	- [[Text Summarization]]
	- [[Question Answering]]
	- [[Dialogue Systems]]
	- [[Text Classification]]
	- [[Named Entity Recognition]]
	- [[Language Modeling]]
	- [[Text Generation]]
	- [[Code Generation]]
- [[Audio Processing]]
	- [[Audio Classification]]
	- [[Speech Recognition]]
	- [[Music Generation]]
- [[Computer Vision]]
	- [[Image Classification]]
	- [[Segmentation]]
	- [[Image Captioning]]
	- [[Object Detection]]
	- [[Scene Understanding]]
- [[Multimodal]]
	- [[Optical Character Recognition (OCR)]]
	- [[Information Extraction]]

## Notes
### Further Readings
- ![[Attention is All You Need.pdf]]